{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
      "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
      "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
      "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
      "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
      "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
      "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate', 'attack', ' last_flag', 'separator'],\n",
      "      dtype='object')\n",
      "(148517, 44)\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "\n",
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#importing the dataset\n",
    "#train_dataset = pd.read_csv('C:\\\\Users\\\\ds00327948\\\\Downloads\\\\train.txt')\n",
    "\n",
    "train_dataset = pd.read_csv('C:\\\\Users\\\\ds00327948\\\\Downloads\\\\Train - Header.txt')\n",
    "train_dataset['separator'] = 98\n",
    "test_dataset = pd.read_csv('C:\\\\Users\\\\ds00327948\\\\Downloads\\\\test - Header.txt')\n",
    "test_dataset['separator'] = 99\n",
    "\n",
    "#print(train_dataset.columns)\n",
    "#print(test_dataset.columns)\n",
    "\n",
    "#print(test_dataset.shape)\n",
    "\n",
    "result = pd.concat([train_dataset,test_dataset])\n",
    "\n",
    "print (result.columns)\n",
    "print (result.shape)\n",
    "#train_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
      "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
      "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
      "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
      "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
      "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
      "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate', 'separator', 'Attack'],\n",
      "      dtype='object')\n",
      "(148517, 43)\n"
     ]
    }
   ],
   "source": [
    "def Attack_cat(c):\n",
    "  if c['attack'] == 'normal':\n",
    "    return 'normal'\n",
    "  else:\n",
    "    return 'attack'\n",
    "\n",
    "result['Attack'] = result.apply(Attack_cat, axis=1)\n",
    "result.drop(['attack',' last_flag'],axis=1,inplace=True)\n",
    "\n",
    "print(result.columns)\n",
    "print (result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = result.iloc[:, :-1].values\n",
    "y = result.iloc[:, 42].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148517, 114)\n",
      "(148517,)\n"
     ]
    }
   ],
   "source": [
    "#encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_x_1 = LabelEncoder()\n",
    "labelencoder_x_2 = LabelEncoder()\n",
    "labelencoder_x_3 = LabelEncoder()\n",
    "\n",
    "x[:, 1] = labelencoder_x_1.fit_transform(x[:, 1])\n",
    "x[:, 2] = labelencoder_x_2.fit_transform(x[:, 2])\n",
    "x[:, 3] = labelencoder_x_3.fit_transform(x[:, 3])\n",
    "onehotencoder_1 = OneHotEncoder(categorical_features = [1])\n",
    "x = onehotencoder_1.fit_transform(x).toarray()\n",
    "onehotencoder_2 = OneHotEncoder(categorical_features = [4])\n",
    "x = onehotencoder_2.fit_transform(x).toarray()\n",
    "onehotencoder_3 = OneHotEncoder(categorical_features = [70])\n",
    "x = onehotencoder_3.fit_transform(x).toarray()\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_result=pd.DataFrame(x)\n",
    "encoded_result[114] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
      "            ...\n",
      "            105, 106, 107, 108, 109, 110, 111, 112, 113, 114],\n",
      "           dtype='int64', length=115)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_result.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8    9   ...    105   106   107  \\\n",
      "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.17  0.03  0.17   \n",
      "1  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.00  0.60  0.88   \n",
      "2  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.10  0.05  0.00   \n",
      "3  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.00  0.00  0.03   \n",
      "4  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.00  0.00  0.00   \n",
      "\n",
      "    108   109   110   111   112   113  114  \n",
      "0  0.00  0.00  0.00  0.05  0.00  98.0    1  \n",
      "1  0.00  0.00  0.00  0.00  0.00  98.0    1  \n",
      "2  0.00  1.00  1.00  0.00  0.00  98.0    0  \n",
      "3  0.04  0.03  0.01  0.00  0.01  98.0    1  \n",
      "4  0.00  0.00  0.00  0.00  0.00  98.0    1  \n",
      "\n",
      "[5 rows x 115 columns]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 115)\n",
      "(22544, 115)\n"
     ]
    }
   ],
   "source": [
    "train_df = encoded_result[encoded_result[113] == 98]\n",
    "test_df = encoded_result[encoded_result[113] == 99]\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = train_df.iloc[:, :-2].values\n",
    "y_train = train_df.iloc[:, 114].values\n",
    "\n",
    "\n",
    "x_test = test_df.iloc[:, :-2].values\n",
    "y_test = test_df.iloc[:, 114].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22544, 113)\n",
      "(125973, 113)\n"
     ]
    }
   ],
   "source": [
    "print (x_test.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22544, 113)\n",
      "(125973, 113)\n"
     ]
    }
   ],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)\n",
    "\n",
    "print (x_test.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=113, units=60, kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=60, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=60, kernel_initializer=\"uniform\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125973/125973 [==============================] - 13s 103us/step - loss: 0.0397 - acc: 0.9867\n",
      "Epoch 2/20\n",
      "125973/125973 [==============================] - 12s 94us/step - loss: 0.0240 - acc: 0.9921\n",
      "Epoch 3/20\n",
      "125973/125973 [==============================] - 12s 98us/step - loss: 0.0213 - acc: 0.9931\n",
      "Epoch 4/20\n",
      "125973/125973 [==============================] - 12s 94us/step - loss: 0.0192 - acc: 0.9938\n",
      "Epoch 5/20\n",
      "125973/125973 [==============================] - 12s 95us/step - loss: 0.0188 - acc: 0.9943\n",
      "Epoch 6/20\n",
      "125973/125973 [==============================] - 13s 100us/step - loss: 0.0179 - acc: 0.9947\n",
      "Epoch 7/20\n",
      "125973/125973 [==============================] - 12s 95us/step - loss: 0.0170 - acc: 0.9951\n",
      "Epoch 8/20\n",
      "125973/125973 [==============================] - 13s 99us/step - loss: 0.0162 - acc: 0.9954\n",
      "Epoch 9/20\n",
      "125973/125973 [==============================] - 13s 103us/step - loss: 0.0162 - acc: 0.9954\n",
      "Epoch 10/20\n",
      "125973/125973 [==============================] - 13s 102us/step - loss: 0.0157 - acc: 0.9956\n",
      "Epoch 11/20\n",
      "125973/125973 [==============================] - 13s 101us/step - loss: 0.0159 - acc: 0.9956\n",
      "Epoch 12/20\n",
      "125973/125973 [==============================] - 13s 102us/step - loss: 0.0151 - acc: 0.9959\n",
      "Epoch 13/20\n",
      "125973/125973 [==============================] - 13s 103us/step - loss: 0.0149 - acc: 0.9960\n",
      "Epoch 14/20\n",
      "125973/125973 [==============================] - 13s 101us/step - loss: 0.0142 - acc: 0.9959\n",
      "Epoch 15/20\n",
      "125973/125973 [==============================] - 13s 100us/step - loss: 0.0141 - acc: 0.9963\n",
      "Epoch 16/20\n",
      "125973/125973 [==============================] - 13s 100us/step - loss: 0.0150 - acc: 0.9960\n",
      "Epoch 17/20\n",
      "125973/125973 [==============================] - 13s 100us/step - loss: 0.0146 - acc: 0.9961\n",
      "Epoch 18/20\n",
      "125973/125973 [==============================] - 13s 101us/step - loss: 0.0170 - acc: 0.9961\n",
      "Epoch 19/20\n",
      "125973/125973 [==============================] - 14s 111us/step - loss: 0.0140 - acc: 0.9963\n",
      "Epoch 20/20\n",
      "125973/125973 [==============================] - 13s 103us/step - loss: 0.0150 - acc: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d03880668>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 60, init = 'uniform', activation = 'relu', input_dim = 113))\n",
    "\n",
    "#Adding a second hidden layer\n",
    "classifier.add(Dense(output_dim = 60, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "#Adding a third hidden layer\n",
    "classifier.add(Dense(output_dim = 60, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(x_train, y_train, batch_size = 10, nb_epoch = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8260 4573]\n",
      " [ 720 8991]]\n",
      "the Accuracy is: 0.7652146912704045\n",
      "Recall is : 0.6628575641403716\n",
      "False Positive rate: 0.0801781737193764\n",
      "Precision is: 0.9258572752548656\n",
      "F-measure is: 0.7725886143931255\n",
      "Entropy is: 0.07132358797309692\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print ( cm)\n",
    "\n",
    "#the performance of the classification model\n",
    "print(\"the Accuracy is: \"+ str((cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])))\n",
    "recall = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "print(\"Recall is : \"+ str(recall))\n",
    "print(\"False Positive rate: \"+ str(cm[1,0]/(cm[0,0]+cm[1,0])))\n",
    "precision = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Precision is: \"+ str(precision))\n",
    "print(\"F-measure is: \"+ str(2*((precision*recall)/(precision+recall))))\n",
    "from math import log\n",
    "print(\"Entropy is: \"+ str(-precision*log(precision)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
